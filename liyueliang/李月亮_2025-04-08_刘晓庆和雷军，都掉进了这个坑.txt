刘晓庆和雷军，都掉进了这个坑

点击??下方小卡片关注月亮
文丨李月亮 七野每晚八点四十 陪你看世事·点击收听本文音频·
AI是很美好的东西。但也可能是伤人的利器。
01李月亮?
前阵子，有粉丝给刘晓庆留言。
说有一个视频账号，发了很多刘晓庆的视频，但里面很多话明显不是刘晓庆说的，应该是AI生成的。
比如这个账号里，有个刘晓庆演讲的视频。
她在里面讲自己“出狱当天连吃了三碗炸酱面”。
——这是根本没有的事儿。
刘晓庆自己点进去一看，也惊了——
“天哪，画面是我，声音很像我，但不是我！
这是怎么做到的？
以后大家不会搞不清哪个才是真的我了吧？”
简直是现实版真假美猴王。
关键假刘晓庆账号流量还很大，点赞成千上万。
评论区也非常热闹，好多不明真相的网友在热烈发言。
更可怕的是，这种号还很泛滥。
雷军也掉过这个坑。
——准确说，一直在坑里。
这两年，网上特别流行用“AI雷军”做配音。
用雷军的声音，说各种离谱的话。
有时候疯狂骂人，有时候胡说八道——
“你们年轻人整天就知道TMD扯淡！”
“我打算用50亿投资安徽农业大学，谁要阻拦我，我就远程操控小米SU7把他撞飞！”
这种假视频，不仔细分辨很容易信以为真。
雷军深受困扰，但是也没什么办法。
他一再告诫网友不要这么恶搞。
但是这个风根本刹不住。
到现在还有人收钱教人如何制造“AI雷军语音”。
有内行的网友告诉刘晓庆，现在的AI只要输入你的形象和台词，就能自动生成你的视频。
做视频的人想让你说什么，你就说什么，想让你卖什么，你就卖什么。
你说吓不吓人。
02李月亮?
不得不说，现在AI的发展堪称炸裂。
经常上网的人，每天都会不知不觉地看一堆AI生成的视频。
有些AI视频没啥坏处，就是图个乐呵。
比如甄嬛举起“屠龙枪”。
比如林妹妹大战贾宝玉。
这些视频一看就是假的，大家乐呵乐呵就过去了。
算是人畜无害。
而有些AI视频，问题就大了。
比如造假重灾区——AI小孩和AI宠物。
这种虎头虎脑的AI大胖孙子，很多人都刷到过。
打开短视频软件，一排白白胖胖的小孩朝你招手。
驮着大猪蹄，顶着烤乳猪。
又好看又能干。
三岁就能摘菜、洗菜。
一个人做出四菜一汤。
这群大胖孙子把很多老年人哄得挪不开眼。
动不动转发到家人群，“看看人家这小孩”。
言外之意，敦促儿子儿媳女儿女婿都学着点，好好教教自己那个不成器的娃，人家三岁都能做四菜一汤了，你瞅瞅你养那个，鞋都穿不上。
咱就说这玩意得引发多少家庭矛盾。
有位网友过年回家探望老人。
发现奶奶根本不搭理他，反倒对着手机里的假孙子哎了半个小时。
他说那是假的，奶奶根本不相信。
现在“AI大胖孙子”，已经流传到动物界了。
小狗炖鸡汤。
小猫摆摊卖炒饭。
最常见的是一只小橘猫。
一会儿救老奶奶，一会儿救白娘子。
可给它忙坏了。
03李月亮?
好在，这种AI视频毕竟好识别，危害还算小。
很多卖药带货的AI数字人，才贻害无穷。
像这种一头白发的“金牌老中医”。
经常在镜头前娓娓道来，传授她的养生技巧。
乍看很让人信服。
但事实上，她是个AI生成的“数字老专家”。
从形象到声音，到文案，到头衔，都是凭空伪造的。
是个彻头彻尾的冒牌货。
而这种“数字专家”们说的话，更是蒙人。
看似有道理，实则比鬼话还离谱——
按揉大拇指的穴位可以治愈近视。
拍打左肩膀能彻底治好心脏病。
每天吃三颗红枣，贫血立刻好。
喝绿豆汤包治百病，所有药都让你停掉……
所谓“独家秘方”，其实都是他们瞎编的。
所谓“临床研究数据”，根本没有人临床研究过。
你要是信他们，指不定掉啥坑里去。
有网友试过了。
跟着上面那个老太太做养生的动作，最后会变成这样。
更别提跟着她求医问药了。
@小宇在农村
这种“数字专家”，很有迷惑性。
有时候打眼一看，真看不出是假的。
比如这位哥们。
有皱纹，有痘印，脸上还出了点油。
看面相就是业主群里的一个普通邻居。
但他其实是个挺出名的AI人，叫“王建国”。
别看其貌不扬，走的还是“蛊惑人心”的情感赛道。
打开短视频平台，王建国从花丛里钻出来。
嘴甜心暖，卯着劲哄老姐姐们开心。
时不时还动一动感情。
眼眶微微泛红，害羞地袒露心意：
“连睡梦里，我都会情不自禁地，叫着你的名字。”
虽然没办法敞开自己的心房。
但是……
他可以向老姐姐们打开橱窗。
他的视频其实有平台的AI标识。
但是很不显眼，一般人都不会注意到。
不少老姐姐被王建国迷得七荤八素，咔咔下单。
后来，王建国还“拖家带口”地上岗。
让他的AI儿子、AI闺女都开始发类似的短视频。
带货效果也不错。
这一家子根本不存在的AI人，不知道给幕后主人赚了多少钱。
这样的AI人，现在越来越多。
喊几句“宝宝姐姐”，就能赚得盆满钵满。
而他的姐姐们可能一直不知道。
你为之撒钱的弟弟，根本不是人。
因为AI是机器生成的产物。一旦出事，账号注销跑路。
受害者要找到机器背后的人维权，十分困难。
04李月亮?
刘晓庆遇到的陷阱，是AI技术的进阶版，叫“深度伪造”。
这个技术，用一张真人照片，就能生成说话、跳舞、卖货的视频。
并且做得惟妙惟肖。
靳东、陈建斌、刘德华……很多知名人物都是受害者。
前阵子，张伯礼院士也在央视辟谣。
说有不少人用他的形象做AI广告，带货护肤品、卖药。
他气愤又忧心：
“对我的影响还是第二位的，最可怕的是这些东西误导消费者，让老百姓买到假药。”
更让人忧心的是，这个技术也会被用在普通人身上。
北京的69岁徐大爷，因为拍了条视频。
莫名其妙被人用AI改造成了“90岁患癌老人”。
通过讲述离奇的经历，骗网友买抗癌神药。
有一天，他在天坛公园锻炼，遇到了看过他广告的人。
那人气势汹汹地问他赚了多少黑心钱。
他才知道，自己早就被“上链接”了。
05李月亮?
那么如何防范这无孔不入的AI坑呢？
其实也不难。
学会以下几个小技巧，基本就不会踩坑了：
第一，最直接的办法，就是去看视频下方有没有AI标识。
大部分AI视频都能被系统识别，贴上标签。
第二，对于没有标识的视频，可以观察他们的面部特征。
AI一般会出现一种“机器长相”。
皮肤光滑、五官不协调、没有清晰的头发丝儿。第三，还可以通过一些细节看出AI痕迹——眨眼频率过快或者过慢。
牙齿边缘过于整齐。
瞳孔颜色两边不一样（比如一个黑，一个棕，因为融合了不同人的脸）。
第四，看他说的话、做的事是否符合常识。
对于违反常识、又说不清来源的言论，不要轻信。
第五，如果有亲友打来电话或视频借钱，要当心AI骗局。
可以要求他在镜头前挥挥手，观察脸部有没有明显不正常的抖动。
或者问一些只有对方才知道的问题，验证那边是不是本人。
第六，求证AI问题的时候，不要过于相信它。
现在我们经常会找AI问各种问题。
这就需要有一个基本常识：
AI亲口回答你的内容，不能完全相信。
因为AI技术背靠的信息池，像一本巨大的百科书。
所有网友说的话，不管真假，它都照单收录。
所以，它可能会天马行空地说一些根本不存在的东西。
而且说得有鼻子有眼。
也因为信息被污染，AI有时连一些简单的问题都答不对。
告诉你过完一轮12生肖，需要13.5年。
1000天前是2023年。
有时是因为问到了知识盲区。
触及了AI的自由创作机制，让它开始一本正经地胡说八道。
清华大学的研究团队发现，AI的幻觉率高达30%。
差不多问它三次问题，它就可能犯一次迷糊。
因为内容生产的机制存在硬伤，哪怕最先进的AI，都逃脱不了出现幻觉的麻烦。
如果你一定要使用AI查找信息，可以借助“三角求证法”。
问三个AI产品同一个问题。
一般会得到比较靠谱的答案。
这个时代，AI已经成为人们的得力助手。
但我们在利用AI的同时，也要提升对它的认知。
避免被AI蒙蔽。
毕竟越好的东西，越可能是伤人的利器。
谢谢你看完文章，如果你也认同，还请点亮【赞】+【在看】。──── 全文完 ────作者简介
本文作者：李月亮。高人气作家，微信公众号【李月亮】每日解读热点，透析人性，以理性和智慧陪读者成长。新书《活得清醒》当当网热卖中。
往期好文点击蓝字即可跳转
| 倪萍，太惨了|刘亦菲和华为副总裁的视频爆火，暴露了男女关系的扎心真相
你的「赞」+「在看」，月亮都看得见??